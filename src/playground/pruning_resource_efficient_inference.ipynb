{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for paper \"Pruning Convolutional Neural Networks for Resource Efficient Inference\"\n",
    "# code adopted from https://github.com/eeric/channel_prune\n",
    "# which itself is adopted from https://github.com/jacobgil/pytorch-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.path[0] != '..':\n",
    "    sys.path.insert(0, '..')\n",
    "    \n",
    "path_ros = '/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "if path_ros in sys.path:\n",
    "    del sys.path[sys.path.index(path_ros)]\n",
    "    \n",
    "from networks.osvos_resnet import OSVOS_RESNET\n",
    "from util import io_helper\n",
    "from layers.osvos_layers import class_balanced_cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net() -> nn.Module:\n",
    "    net = OSVOS_RESNET(pretrained=False)\n",
    "    path_model = Path('../models/resnet18_11_11_blackswan_epoch-9999.pth')\n",
    "    parameters = torch.load(str(path_model), map_location=lambda storage, loc: storage)\n",
    "    net.load_state_dict(parameters)\n",
    "    net = net.cuda()\n",
    "    return net\n",
    "\n",
    "net = get_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_num_filters(net: nn.Module) -> int:\n",
    "    n_filters = 0\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            n_filters += m.out_channels\n",
    "    return n_filters\n",
    "\n",
    "n_filters = total_num_filters(net)\n",
    "n_filters_to_prune_per_iter = 512\n",
    "n_iterations = int(n_filters / n_filters_to_prune_per_iter * 2 / 3)\n",
    "\n",
    "print('Filters in model:', n_filters)\n",
    "print('Prune n filters per iteration:', n_filters_to_prune_per_iter)\n",
    "print('Number of iterations:', n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterPruner:\n",
    "    def __init__(self, net: nn.Module):\n",
    "        self.net = net\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.filter_ranks = {}\n",
    "        # different from original code\n",
    "        self.net.zero_grad()\n",
    "        \n",
    "    def forward(self) -> None:\n",
    "        pass\n",
    "\n",
    "pruner = FilterPruner(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = io_helper.get_data_loader_test(Path('/home/klaus/dev/datasets/DAVIS'), batch_size=1, seq_name='blackswan')\n",
    "\n",
    "def train(pruner: FilterPruner, data_loader: data.DataLoader, n_epochs: Optional[int] = 1) -> None:\n",
    "    for epoch in range(n_epochs):\n",
    "        for minibatch_index, minibatch in enumerate(data_loader):\n",
    "            inputs, gts = minibatch['image'], minibatch['gt']\n",
    "            inputs, gts = Variable(inputs), Variable(gts)\n",
    "            inputs, gts = inputs.cuda(), gts.cuda()\n",
    "            \n",
    "            outputs = pruner.forward(inputs)\n",
    "            loss = class_balanced_cross_entropy_loss(outputs[-1], gts, size_average=False)\n",
    "            loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates_to_prune(pruner: FilterPruner, n_filters_to_prune: int, net: nn.Module, data_loader: data.DataLoader) -> None:\n",
    "    pruner.reset()\n",
    "    train(pruner, data_loader)\n",
    "    pruner.normalize_ranks_per_layer()\n",
    "    return prunner.get_prunning_plan(n_filters_to_prune)\n",
    "\n",
    "print('Ranking filters')\n",
    "prune_targets = get_candidates_to_prune(pruner, n_filters_to_prune_per_iter, net, data_loader)\n",
    "layers_prunned = {}\n",
    "for layer_index, filter_index in prune_targets:\n",
    "    if layer_index not in layers_prunned:\n",
    "        layers_prunned[layer_index] = 0\n",
    "    layers_prunned[layer_index] = layers_prunned[layer_index] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

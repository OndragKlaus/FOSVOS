{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for paper \"Pruning Convolutional Neural Networks for Resource Efficient Inference\"\n",
    "# code adopted from https://github.com/eeric/channel_prune\n",
    "# which itself is adopted from https://github.com/jacobgil/pytorch-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "import operator\n",
    "import heapq\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.path[0] != '..':\n",
    "    sys.path.insert(0, '..')\n",
    "    \n",
    "path_ros = '/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "if path_ros in sys.path:\n",
    "    del sys.path[sys.path.index(path_ros)]\n",
    "    \n",
    "from networks.osvos_resnet import OSVOS_RESNET\n",
    "from util import io_helper\n",
    "from layers.osvos_layers import class_balanced_cross_entropy_loss, center_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net() -> nn.Module:\n",
    "    net = OSVOS_RESNET(pretrained=False)\n",
    "    path_model = Path('../models/resnet18_11_11_blackswan_epoch-9999.pth')\n",
    "    parameters = torch.load(str(path_model), map_location=lambda storage, loc: storage)\n",
    "    net.load_state_dict(parameters)\n",
    "    # net = net.cuda()\n",
    "    return net\n",
    "\n",
    "net = get_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_num_filters(net: nn.Module) -> int:\n",
    "    n_filters = 0\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            n_filters += m.out_channels\n",
    "        if n_filters > 0:\n",
    "            return n_filters\n",
    "    return n_filters\n",
    "\n",
    "n_filters = total_num_filters(net)\n",
    "# n_filters_to_prune_per_iter = 512\n",
    "n_filters_to_prune_per_iter = 8\n",
    "n_iterations = int(n_filters / n_filters_to_prune_per_iter * 2 / 3)\n",
    "\n",
    "print('Filters in model:', n_filters)\n",
    "print('Prune n filters per iteration:', n_filters_to_prune_per_iter)\n",
    "print('Number of iterations:', n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterPruner:\n",
    "    def __init__(self, net: nn.Module):\n",
    "        self.net = net\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.filter_ranks = {}\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.activations = []\n",
    "        self.gradients = []\n",
    "        self.grad_index = 0\n",
    "        self.activation_to_layer = {}\n",
    "        activation_index = 0\n",
    "        kk = 0\n",
    "        \n",
    "        crop_h, crop_w = int(x.size()[-2]), int(x.size()[-1])\n",
    "        \n",
    "        for l in self.net.layer_base:\n",
    "            x = l(x)\n",
    "            if isinstance(l, torch.nn.modules.conv.Conv2d):\n",
    "                x.register_hook(self.compute_rank)\n",
    "                self.activations.append(x)\n",
    "                self.activation_to_layer[activation_index] = kk\n",
    "                activation_index += 1\n",
    "                kk += 1\n",
    "        # x = self.net.layer_base(x)\n",
    "        \n",
    "        side = []\n",
    "        side_out = []\n",
    "        for (layer_stage, layer_side_prep, layer_upscale_side_prep,\n",
    "             layer_score_dsn, layer_upscale_score_dsn) in zip(self.net.layer_stages, self.net.side_prep,\n",
    "                                                              self.net.upscale_side_prep,\n",
    "                                                              self.net.score_dsn, self.net.upscale_score_dsn):\n",
    "            x = layer_stage(x)\n",
    "            temp_side_prep = layer_side_prep(x)\n",
    "\n",
    "            temp_upscale = layer_upscale_side_prep(temp_side_prep)\n",
    "            temp_cropped = center_crop(temp_upscale, crop_h, crop_w)\n",
    "            side.append(temp_cropped)\n",
    "\n",
    "            temp_score_dsn = layer_score_dsn(temp_side_prep)\n",
    "            temp_upscale_ = layer_upscale_score_dsn(temp_score_dsn)\n",
    "            temp_cropped_ = center_crop(temp_upscale_, crop_h, crop_w)\n",
    "            side_out.append(temp_cropped_)\n",
    "\n",
    "        out = torch.cat(side[:], dim=1)\n",
    "        out = self.net.layer_fuse(out)\n",
    "        side_out.append(out)\n",
    "        return side_out\n",
    "\n",
    "    def compute_rank(self, grad):\n",
    "        activation_index = len(self.activations) - self.grad_index - 1\n",
    "        activation = self.activations[activation_index]\n",
    "        values = torch.sum((activation * grad), dim=0, keepdim=True).sum(dim=2, keepdim=True).sum(dim=3, keepdim=True)[0, :, 0, 0].data\n",
    "\n",
    "        # Normalize the rank by the filter dimensions\n",
    "        values = values / (activation.size(0) * activation.size(2) * activation.size(3))\n",
    "\n",
    "        if activation_index not in self.filter_ranks:\n",
    "            # self.filter_ranks[activation_index] = torch.FloatTensor(activation.size(1)).zero_().cuda()\n",
    "            self.filter_ranks[activation_index] = torch.FloatTensor(activation.size(1)).zero_()\n",
    "\n",
    "        self.filter_ranks[activation_index] += values\n",
    "        self.grad_index += 1\n",
    "    \n",
    "    def normalize_ranks_per_layer(self):\n",
    "        for i in self.filter_ranks:\n",
    "            v = torch.abs(self.filter_ranks[i])\n",
    "            v = v / np.sqrt(torch.sum(v * v))\n",
    "            self.filter_ranks[i] = v.cpu()\n",
    "\n",
    "    def lowest_ranking_filters(self, n_filters_to_prune_per_iter):\n",
    "        data = []\n",
    "        for i in sorted(self.filter_ranks.keys()):\n",
    "            for j in range(self.filter_ranks[i].size(0)):\n",
    "                data.append((self.activation_to_layer[i], j, self.filter_ranks[i][j]))\n",
    "\n",
    "        return heapq.nsmallest(n_filters_to_prune_per_iter, data, operator.itemgetter(2))\n",
    "            \n",
    "    def get_prunning_plan(self, n_filters_to_prune_per_iter):\n",
    "        filters_to_prune = self.lowest_ranking_filters(n_filters_to_prune_per_iter)\n",
    "\n",
    "        # After each of the k filters are prunned,\n",
    "        # the filter index of the next filters change since the model is smaller.\n",
    "        filters_to_prune_per_layer = {}\n",
    "        for (l, f, _) in filters_to_prune:\n",
    "            if l not in filters_to_prune_per_layer:\n",
    "                filters_to_prune_per_layer[l] = []\n",
    "            filters_to_prune_per_layer[l].append(f)\n",
    "\n",
    "        for l in filters_to_prune_per_layer:\n",
    "            filters_to_prune_per_layer[l] = sorted(filters_to_prune_per_layer[l])\n",
    "            for i in range(len(filters_to_prune_per_layer[l])):\n",
    "                filters_to_prune_per_layer[l][i] = filters_to_prune_per_layer[l][i] - i\n",
    "\n",
    "        filters_to_prune = []\n",
    "        for l in filters_to_prune_per_layer:\n",
    "            for i in filters_to_prune_per_layer[l]:\n",
    "                filters_to_prune.append((l, i))\n",
    "\n",
    "        return filters_to_prune\n",
    "\n",
    "pruner = FilterPruner(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = io_helper.get_data_loader_test(Path('/home/klaus/dev/datasets/DAVIS'), batch_size=1, seq_name='blackswan')\n",
    "\n",
    "def train(pruner: FilterPruner, data_loader: data.DataLoader, n_epochs: Optional[int] = 1) -> None:\n",
    "    for epoch in range(n_epochs):\n",
    "        for minibatch in tqdm(data_loader):\n",
    "            pruner.net.zero_grad()\n",
    "            inputs, gts = minibatch['image'], minibatch['gt']\n",
    "            inputs, gts = Variable(inputs), Variable(gts)\n",
    "            # inputs, gts = inputs.cuda(), gts.cuda()\n",
    "            \n",
    "            outputs = pruner.forward(inputs)\n",
    "            loss = class_balanced_cross_entropy_loss(outputs[-1], gts, size_average=False)\n",
    "            loss.backward()\n",
    "            return\n",
    "            \n",
    "def fine_tune(net: nn.Module(), data_loader: data.DataLoader, n_epochs: Optional[int] = 1) -> None:\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-4, weight_decay=0.0002)\n",
    "    avg_grad_every_n = 5\n",
    "    counter_gradient = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for minibatch in tqdm(data_loader):\n",
    "            net.zero_grad()\n",
    "            inputs, gts = minibatch['image'], minibatch['gt']\n",
    "            inputs, gts = Variable(inputs), Variable(gts)\n",
    "            # inputs, gts = inputs.cuda(), gts.cuda()\n",
    "            \n",
    "            outputs = net.forward(inputs)\n",
    "            loss = class_balanced_cross_entropy_loss(outputs[-1], gts, size_average=False)\n",
    "            loss /= avg_grad_every_n\n",
    "            loss.backward()\n",
    "            counter_gradient += 1\n",
    "\n",
    "            if counter_gradient % avg_grad_every_n == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_resnet18_conv_layer(net, layer_index, filter_index):\n",
    "    next_conv = None\n",
    "    next_new_conv = None\n",
    "    downin_conv = None\n",
    "    downout_conv = None\n",
    "    next_downin_conv = None\n",
    "    new_down_conv = None\n",
    "    print(layer_index)\n",
    "    print(filter_index)\n",
    "    \n",
    "    if layer_index == 0:\n",
    "        conv = net.layer_base[0]\n",
    "        next_conv = net.layer_stages[0][0].conv1\n",
    "    \n",
    "    new_conv = torch.nn.Conv2d(in_channels=conv.in_channels, \n",
    "                               out_channels=conv.out_channels - 1,\n",
    "                               kernel_size=conv.kernel_size,\n",
    "                               stride=conv.stride,\n",
    "                               padding=conv.padding,\n",
    "                               dilation=conv.dilation,\n",
    "                               groups=conv.groups,\n",
    "                               bias=conv.bias)\n",
    "\n",
    "    old_weights = conv.weight.data.cpu().numpy()\n",
    "    new_weights = new_conv.weight.data.cpu().numpy()\n",
    "\n",
    "    new_weights[:filter_index, :, :, :] = old_weights[:filter_index, :, :, :]\n",
    "    new_weights[filter_index:, :, :, :] = old_weights[filter_index + 1:, :, :, :]\n",
    "    # new_conv.weight.data = torch.from_numpy(new_weights).cuda()\n",
    "    new_conv.weight.data = torch.from_numpy(new_weights)\n",
    "    \n",
    "    if next_conv is not None:\n",
    "        next_new_conv = torch.nn.Conv2d(in_channels=next_conv.in_channels - 1, \n",
    "                                        out_channels=next_conv.out_channels,\n",
    "                                        kernel_size=next_conv.kernel_size,\n",
    "                                        stride=next_conv.stride,\n",
    "                                        padding=next_conv.padding,\n",
    "                                        dilation=next_conv.dilation,\n",
    "                                        groups=next_conv.groups,\n",
    "                                        bias=next_conv.bias)\n",
    "\n",
    "        old_weights = next_conv.weight.data.cpu().numpy()\n",
    "        new_weights = next_new_conv.weight.data.cpu().numpy()\n",
    "\n",
    "        new_weights[:, :filter_index, :, :] = old_weights[:, :filter_index, :, :]\n",
    "        new_weights[:, filter_index:, :, :] = old_weights[:, filter_index + 1:, :, :]\n",
    "        # next_new_conv.weight.data = torch.from_numpy(new_weights).cuda()\n",
    "        next_new_conv.weight.data = torch.from_numpy(new_weights)\n",
    "\n",
    "        if not next_conv is None:\n",
    "            if layer_index == 0:\n",
    "                net.layer_base = nn.Sequential(new_conv, *list(net.layer_base.children())[1:])\n",
    "                # net.layer_base[0] = new_conv\n",
    "                net.layer_stages[0][0].conv1 = next_new_conv\n",
    "        \n",
    "    return net\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates_to_prune(pruner: FilterPruner, n_filters_to_prune: int, net: nn.Module, data_loader: data.DataLoader) -> None:\n",
    "    pruner.reset()\n",
    "    train(pruner, data_loader)\n",
    "    pruner.normalize_ranks_per_layer()\n",
    "    return pruner.get_prunning_plan(n_filters_to_prune)\n",
    "\n",
    "print('Ranking filters')\n",
    "prune_targets = get_candidates_to_prune(pruner, n_filters_to_prune_per_iter, net, data_loader)\n",
    "layers_prunned = {}\n",
    "for layer_index, filter_index in prune_targets:\n",
    "    if layer_index not in layers_prunned:\n",
    "        layers_prunned[layer_index] = 0\n",
    "    layers_prunned[layer_index] = layers_prunned[layer_index] + 1\n",
    "    print(\"Layers that will be prunned\", layers_prunned)\n",
    "    print(\"Prunning filters.. \")\n",
    "    net = net.cpu()\n",
    "    for layer_index, filter_index in prune_targets:\n",
    "        # TODO: implement\n",
    "        net = prune_resnet18_conv_layer(net, layer_index, filter_index)\n",
    "        \n",
    "        break\n",
    "    break\n",
    "    \n",
    "    # TODO: implement\n",
    "    net = self.batchnorm_modify()\n",
    "    # net = net.cuda()\n",
    "    print(\"Plan to prune...\", net)\n",
    "    \n",
    "    message = str(100 * total_num_filters(net) / n_filters) + \"%\"\n",
    "    print(\"Filters prunned\", str(message))\n",
    "    # TODO: implement\n",
    "    # test()\n",
    "    print(\"Fine tuning to recover from prunning iteration.\")\n",
    "    fine_tune(data_loader, n_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

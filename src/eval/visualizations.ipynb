{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations for fast-osvos\n",
    "## Evaluating both vgg16, resnet18 and resnet34\n",
    "For all three architectures, both offline and online models are shown. The best performing online models represent their corresponding architectures. The offline models are chosen based on the online models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('webagg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import imageio\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_resnet18_offline, variant_resnet18_online = 11, 11\n",
    "variant_resnet34_offline, variant_resnet34_online = 11, 11\n",
    "\n",
    "base_path_results = '/home/klaus/dev/fast-osvos/src/results/'\n",
    "base_path_dataset = '/home/klaus/dev/datasets/DAVIS/'\n",
    "base_paths = [('Original Image', base_path_dataset + 'JPEGImages/480p/'),\n",
    "              ('Ground Truth', base_path_dataset + 'Annotations/480p/'),\n",
    "              ('vgg16', base_path_results + 'vgg16/online/'),\n",
    "              ('resnet18', base_path_results + 'resnet18/{0}/{1}/'.format(variant_resnet18_offline,\n",
    "                                                                          variant_resnet18_online)), \n",
    "              ('resnet34', base_path_results + 'resnet34/{0}/{1}/'.format(variant_resnet34_offline,\n",
    "                                                                            variant_resnet34_online))]\n",
    "\n",
    "models = ['vgg16_offline', 'resnet18_offline', 'resnet34_offline',\n",
    "          'vgg16_online', 'resnet18_online', 'resnet34_online']\n",
    "\n",
    "base_path_eval = '/home/klaus/dev/davis-2017-fork/python/tools/output/metrics_mine_'\n",
    "file_paths_eval = {\n",
    "    'vgg16_offline': base_path_eval + 'vgg16_offline.yml',\n",
    "    'resnet18_offline': base_path_eval + 'resnet18_{0}_offline.yml'.format(variant_resnet18_offline),\n",
    "    'resnet34_offline': base_path_eval + 'resnet34_{0}_offline.yml'.format(variant_resnet34_offline),\n",
    "    'vgg16_online': base_path_eval + 'vgg16_online.yml',\n",
    "    'resnet18_online': base_path_eval + 'resnet18_{0}_{1}.yml'.format(variant_resnet18_offline,\n",
    "                                                                      variant_resnet18_online),\n",
    "    'resnet34_online': base_path_eval + 'resnet34_{0}_{1}.yml'.format(variant_resnet34_offline,\n",
    "                                                                      variant_resnet34_offline)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_speeds = [('vgg16', 0.08083438105769455), \n",
    "               ('resnet18', 0.010670146435228262),\n",
    "               ('resnet34', 0.013862044609998438)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_for_model(file_path, metrics):\n",
    "    with open(file_path, 'r') as stream:\n",
    "        model_eval = yaml.load(stream)\n",
    "        \n",
    "    metrics = [model_eval['dataset'][base][specific]\n",
    "               for base, specific in metrics]\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def part_better(specific):\n",
    "    if specific == 'decay':\n",
    "        better = '↓'\n",
    "    else:\n",
    "        better = '↑'\n",
    "    return better\n",
    "\n",
    "def get_metrics_all(models):\n",
    "    metrics_base = ['J', 'F']\n",
    "    metrics_specific = ['mean', 'recall', 'decay']\n",
    "    metrics = list(product(metrics_base, metrics_specific))\n",
    "    \n",
    "    metrics_names = [base + '_' + specific + part_better(specific)\n",
    "                     for base, specific in metrics]\n",
    "    metrics_all = [(m, get_metrics_for_model(file_paths_eval[m], metrics))\n",
    "                   for m in models]\n",
    "    return metrics_names, metrics_all\n",
    " \n",
    "metrics_names, data_metrics_all = get_metrics_all(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(file_path, metric, parts):\n",
    "    with open(file_path, 'r') as stream:\n",
    "        model_eval = yaml.load(stream)\n",
    "    keys = sorted(model_eval['sequence'].keys(), reverse=True)\n",
    "    stats = [[model_eval['sequence'][k][metric][p][0] for p in parts]\n",
    "             for k in keys]\n",
    "    part_0, part_1 = list(zip(*stats))\n",
    "    return part_0, part_1, keys\n",
    "\n",
    "def get_data_J(file_paths_eval):    \n",
    "    vgg16_J_mean_offline, vgg16_J_decay_offline, keys = get_metric(file_paths_eval['vgg16_offline'], \n",
    "                                                                   'J', ['mean', 'decay'])\n",
    "\n",
    "    resnet18_J_mean_offline, resnet18_J_decay_offline, _ = get_metric(file_paths_eval['resnet18_offline'],\n",
    "                                                                      'J', ['mean', 'decay'])\n",
    "\n",
    "    resnet34_J_mean_offline,  resnet34_J_decay_offline, _ = get_metric(file_paths_eval['resnet34_offline'],\n",
    "                                                                       'J', ['mean', 'decay'])\n",
    "\n",
    "    vgg16_J_mean_online, vgg16_J_decay_online, _ = get_metric(file_paths_eval['vgg16_online'],\n",
    "                                                              'J', ['mean', 'decay'])\n",
    "\n",
    "    resnet18_J_mean_online, resnet18_J_decay_online, _ = get_metric(file_paths_eval['resnet18_online'],\n",
    "                                                                    'J', ['mean', 'decay'])\n",
    "\n",
    "    resnet34_J_mean_online, resnet34_J_decay_online, _ = get_metric(file_paths_eval['resnet34_online'], \n",
    "                                                                    'J', ['mean', 'decay'])\n",
    "    \n",
    "    data_J_mean = [('vgg16_offline', vgg16_J_mean_offline),\n",
    "                   ('resnet18_offline', resnet18_J_mean_offline),\n",
    "                   ('resnet34_offline', resnet34_J_mean_offline),\n",
    "                   ('vgg16_online', vgg16_J_mean_online), \n",
    "                   ('resnet18_online', resnet18_J_mean_online), \n",
    "                   ('resnet34_online', resnet34_J_mean_online)]\n",
    "    \n",
    "    data_J_decay = [('vgg16_offline', vgg16_J_decay_offline),\n",
    "                    ('resnet18_offline', resnet18_J_decay_offline), \n",
    "                    ('resnet34_offline', resnet34_J_decay_offline),\n",
    "                    ('vgg16_online', vgg16_J_decay_online), \n",
    "                    ('resnet18_online', resnet18_J_decay_online), \n",
    "                    ('resnet34_online', resnet34_J_decay_online)]\n",
    "    \n",
    "    return keys, data_J_mean, data_J_decay\n",
    "\n",
    "keys, data_J_mean, data_J_decay = get_data_J(file_paths_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(data, y_axis_label, title):\n",
    "    names, speeds = zip(*data)\n",
    "    data = [go.Bar(y=[speed], x=[name], name=name) for name, speed in data]\n",
    "\n",
    "    layout = go.Layout(title=title,\n",
    "                       font=dict(family='Roboto'),\n",
    "                       xaxis=dict(title='Model', ticks='outside'),\n",
    "                       yaxis=dict(title=y_axis_label),\n",
    "                       showlegend=True\n",
    "                      )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The speeds of the three models were evaluated in a similar fashion as specified in the link\n",
    "\n",
    "https://github.com/jcjohnson/cnn-benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars(data_speeds, y_axis_label='Forward speed per image in seconds',\n",
    "          title='Average forward speed for each model (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_all(keys, data):\n",
    "    data = [go.Bar(y=y, x=keys, name=name, orientation='v') for name, y in data]\n",
    "\n",
    "    layout = go.Layout(title=('Metrics for each model'),\n",
    "                       font=dict(family='Roboto'),\n",
    "                       xaxis=dict(title='Value', ticks='outside'),\n",
    "                       yaxis=dict(title='Metric'),\n",
    "                       showlegend=True,\n",
    "                       bargap=0.33\n",
    "                      )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An overview of the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_all(metrics_names, data_metrics_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(keys, metric, lower_higher, data):\n",
    "    data = [go.Bar(y=keys, x=x, name=name, orientation='h') for name, x in data]\n",
    "    \n",
    "    title = '{metric} per object for each model ({lower_higher} is better)'.format(metric=metric,\n",
    "                                                                                   lower_higher=lower_higher)\n",
    "    layout = go.Layout(title=title,\n",
    "                       font=dict(family='Roboto'),\n",
    "                       xaxis=dict(title=metric,  ticks='outside', side='top'),\n",
    "                       yaxis=dict(title='Object'),\n",
    "                       showlegend=True,\n",
    "                       height=1500,\n",
    "                       bargap=0.33,\n",
    "                       # autosize=False, \n",
    "                       margin=dict(pad=10, t=150, l=100)\n",
    "                      )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An overview over J_mean and J_decay for each object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_metrics(keys, 'J_mean', 'higher', data_J_mean)\n",
    "plot_metrics(keys, 'J_decay', 'lower', data_J_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_rgb(image):\n",
    "    if len(image.shape) == 2:\n",
    "        width, height = image.shape\n",
    "        rgb =  np.empty((width, height, 3), dtype=np.uint8)\n",
    "        rgb[:, :, :] = image[:, :, None]\n",
    "        return rgb\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "def dir_to_images(path):\n",
    "    files = Path(path).iterdir()\n",
    "    files = map(str, files)\n",
    "    files = sorted(files)\n",
    "    files = map(imageio.imread, files)\n",
    "    files = map(convert_to_rgb, files)\n",
    "    files = list(files)\n",
    "    return files\n",
    "\n",
    "def generate_image(frame_sources, n_rows, n_columns, descriptions):\n",
    "    width = 8\n",
    "    height = 8\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    for image_index, image_source in enumerate(frame_sources):\n",
    "        ax = plt.subplot(n_rows, n_columns, image_index + 1)\n",
    "        plt.imshow(image_source)\n",
    "        plt.axis('off')\n",
    "        ax.set_title(descriptions[image_index], fontsize=24, fontname='Roboto')\n",
    "    \n",
    "    image = mplfig_to_npimage(fig)\n",
    "    plt.close()\n",
    "    return image\n",
    "\n",
    "def display_video(category, base_paths):\n",
    "    sources = [(desc, path + category) for desc, path in base_paths]\n",
    "    descriptions, sources = list(zip(*sources))\n",
    "    sources = list(map(dir_to_images, sources))\n",
    "\n",
    "    n_columns = 2\n",
    "    n_rows = len(sources) / n_columns + 1\n",
    "    sources = list(zip(*sources))\n",
    "    \n",
    "    frames = [generate_image(frame_sources, n_rows, n_columns, descriptions) \n",
    "              for frame_sources in tqdm(sources)]\n",
    "    clip = ImageSequenceClip(frames, fps=4)\n",
    "    \n",
    "    display(clip.ipython_display(loop=True))\n",
    "    \n",
    "def display_category(category, base_paths, data_J_mean, data_J_decay):\n",
    "    index_data = keys.index(category)\n",
    "    \n",
    "    title_format = '{0} for each model of the category {1} ({2} is better)'\n",
    "    \n",
    "    data_single_metric = [(desc, metrics[index_data]) for desc, metrics in data_J_mean]\n",
    "    plot_bars(data_single_metric, y_axis_label='J_mean', \n",
    "              title=title_format.format('J_mean', category, 'higher'))\n",
    "    \n",
    "    data_single_metric = [(desc, metrics[index_data]) for desc, metrics in data_J_decay]\n",
    "    plot_bars(data_single_metric, y_axis_label='J_decay', \n",
    "              title=title_format.format('J_decay', category, 'lower'))\n",
    "    \n",
    "    display_video(category, base_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some examples where resnet performs better than vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_category('libby', base_paths, data_J_mean, data_J_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_category('kite-surf', base_paths, data_J_mean, data_J_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_category('horsejump-high', base_paths, data_J_mean, data_J_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some examples where vgg16 is still better (mostly the same objects as in older versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_category('car-shadow', base_paths, data_J_mean, data_J_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_category('motocross-jump', base_paths, data_J_mean, data_J_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_eval = '/home/klaus/dev/davis-2017-fork/python/tools/metrics/'\n",
    "\n",
    "sequences_val = ['blackswan', 'bmx-trees', 'breakdance', 'camel', 'car-roundabout', 'car-shadow', 'cows',\n",
    "                 'dance-twirl', 'dog', 'drift-chicane', 'drift-straight', 'goat', 'horsejump-high', 'kite-surf', \n",
    "                 'libby', 'motocross-jump', 'paragliding-launch', 'parkour', 'scooter-black', 'soapbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(data):\n",
    "    d = []\n",
    "    for k, v in sorted(data.items()):\n",
    "        sequences_names, speeds = list(zip(*v.items()))\n",
    "        trace = go.Box(\n",
    "            x = [k / 100] * len(speeds),\n",
    "            y = speeds,\n",
    "            name = str(k),\n",
    "            legendgroup = str(prune_per_iter),\n",
    "            jitter=0.3,\n",
    "            boxpoints = False,\n",
    "        )\n",
    "        d.append(trace)\n",
    "\n",
    "    layout = go.Layout(title='Forward speed prune {0}'.format(prune_per_iter),\n",
    "                       font=dict(family='Roboto'),\n",
    "                       xaxis=dict(title='Percentage pruned',  ticks='outside', range=(0, 1)),\n",
    "                       yaxis=dict(title='Forward speed in seconds', range=(0.01, 0.025)),\n",
    "                       showlegend=True,\n",
    "                      )\n",
    "    fig = go.Figure(data=d, layout=layout)\n",
    "    py.iplot(fig)\n",
    "    \n",
    "    \n",
    "def plot_line(data):\n",
    "    d = []\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for k, v in sorted(data.items()):\n",
    "        sequences_names, speeds = list(zip(*v.items()))\n",
    "        x.append(k / 100)\n",
    "        y.append(np.asarray(speeds).mean())\n",
    "\n",
    "    trace = go.Scatter(\n",
    "        x = x,\n",
    "        y = y,\n",
    "        name = str(prune_per_iter),\n",
    "        legendgroup = str(prune_per_iter),\n",
    "    )\n",
    "    d.append(trace)\n",
    "\n",
    "    layout = go.Layout(title='Forward speed prune',\n",
    "                       font=dict(family='Roboto'),\n",
    "                       xaxis=dict(title='Percentage pruned',  ticks='outside', range=(0, 1)),\n",
    "                       yaxis=dict(title='Forward speed in seconds', range=(0.01, 0.025)),\n",
    "                       showlegend=True,\n",
    "                      )\n",
    "    fig = go.Figure(data=d, layout=layout)\n",
    "    py.iplot(fig)\n",
    "    \n",
    "    \n",
    "def plot_metric_per_percentage(data):\n",
    "    x = [p / 100 for p in prune_percentages]\n",
    "    y = list(zip(*metrics_all))\n",
    "\n",
    "    d = []\n",
    "\n",
    "    for data_percentage, metric_name in zip(y, metrics_names):\n",
    "        trace = go.Scatter(\n",
    "            x = x,\n",
    "            y = data_percentage,\n",
    "            name = metric_name,\n",
    "            legendgroup = metric_name[0],\n",
    "        )\n",
    "        d.append(trace)\n",
    "\n",
    "    py.iplot(d)\n",
    "    \n",
    "    \n",
    "def get_data_prune():\n",
    "    with open('prune_64.yml'.format(prune_per_iter)) as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    return data\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_prune(data):\n",
    "    # plot_box(data_prune)\n",
    "    # plot_line(data_prune)\n",
    "    \n",
    "    prune_percentages = range(10, 100, 10)\n",
    "    prune_evaluations = ['prune_per_iter={0},percentage={1}.yml'.format(prune_per_iter, p)\n",
    "                         for p in prune_percentages]\n",
    "    prune_evaluations = [(base_path_eval + 'prune/' + p) for p in prune_evaluations]\n",
    "    \n",
    "    \n",
    "    metrics_base = ['J', 'F']\n",
    "    metrics_specific = ['mean', 'recall', 'decay']\n",
    "    metrics = list(product(metrics_base, metrics_specific))\n",
    "\n",
    "    metrics_names = [base + '_' + specific + part_better(specific)\n",
    "                     for base, specific in metrics]\n",
    "    metrics_all = [get_metrics_for_model(p, metrics) for p in prune_evaluations]\n",
    "    \n",
    "    plot_metric_per_percentage(data_prune)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "plot_prune(get_data_prune())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_better(specific):\n",
    "    if specific == 'decay':\n",
    "        better = '↓'\n",
    "    else:\n",
    "        better = '↑'\n",
    "    return better\n",
    "\n",
    "\n",
    "metrics_base = ['J', 'F']\n",
    "metrics_specific = ['mean', 'recall', 'decay']\n",
    "metrics = list(product(metrics_base, metrics_specific))\n",
    "metrics = [metrics[0]]\n",
    "\n",
    "metrics_names = [base + '_' + specific + part_better(specific)\n",
    "                 for base, specific in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, scale, files):\n",
    "    accuracies = []\n",
    "    forward_speeds = []\n",
    "    for a, b in metrics:\n",
    "        data_metrics = {}\n",
    "        for pp, f in zip(scale, files):\n",
    "            with open(f, 'r') as stream:\n",
    "                model_eval = yaml.load(stream)\n",
    "            for k, v in model_eval['sequence'].items():\n",
    "                data_metrics[(pp, k)] = v[a][b][0]\n",
    "\n",
    "        data_speeds = {}\n",
    "        for k in data_metrics.keys():\n",
    "            data_speeds[k] = data[k[0]][k[1]]\n",
    "\n",
    "\n",
    "        tmp_accs = []\n",
    "        tmp_fs = []\n",
    "\n",
    "        for s in scale:\n",
    "            a = []\n",
    "            fs = []\n",
    "            for seq in sequences_val:\n",
    "                a.append(data_metrics[(s, seq)])\n",
    "                fs.append(data_speeds[(s, seq)])\n",
    "            tmp_accs.append(a)\n",
    "            tmp_fs.append(fs)\n",
    "            \n",
    "        accuracies.append(tmp_accs)\n",
    "        forward_speeds.append(tmp_fs)\n",
    "\n",
    "    return forward_speeds, accuracies\n",
    "        \n",
    "\n",
    "names, scales, fs, accs = [], [], [], []\n",
    "    \n",
    "names.append('vgg16')\n",
    "s = [1]\n",
    "files = ['vgg16.yml']\n",
    "files = [(base_path_eval + 'base/' + p) for p in files] \n",
    "with open('vgg16.yml') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "    \n",
    "d = get_data(data, s, files)\n",
    "fs.append(d[0])\n",
    "accs.append(d[1])\n",
    "scales.append(s)\n",
    "\n",
    "    \n",
    "names.append('resnet18')\n",
    "s = [1]\n",
    "files = ['resnet18.yml']\n",
    "files = [(base_path_eval + 'base/' + p) for p in files] \n",
    "with open('resnet18.yml') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "    \n",
    "d = get_data(data, s, files)\n",
    "fs.append(d[0])\n",
    "accs.append(d[1])\n",
    "scales.append(s)\n",
    "\n",
    "    \n",
    "names.append('prune')\n",
    "s = list(range(10, 100, 10))\n",
    "files = ['prune_per_iter=64,percentage={0}.yml'.format(p)\n",
    "         for p in s]\n",
    "files = [(base_path_eval + 'prune/' + p) for p in files] \n",
    "with open('prune.yml') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "    \n",
    "d = get_data(data, s, files)\n",
    "fs.append(d[0])\n",
    "accs.append(d[1])\n",
    "scales.append(s)\n",
    "\n",
    "\n",
    "names.append('mimic_teacher')\n",
    "s = list(range(1, 7))\n",
    "files = ['learn_from=teacher,sde={0}.yml'.format(p)\n",
    "         for p in s]\n",
    "files = [(base_path_eval + 'mimic/' + p) for p in files] \n",
    "with open('mimic_teacher.yml') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "    \n",
    "d = get_data(data, s, files)\n",
    "fs.append(d[0])\n",
    "accs.append(d[1])\n",
    "scales.append(s)\n",
    "\n",
    "\n",
    "names.append('mimic_ground_truth')\n",
    "s = list(range(1, 7))\n",
    "files = ['learn_from=ground_truth,sde={0}.yml'.format(p)\n",
    "         for p in s]\n",
    "files = [(base_path_eval + 'mimic/' + p) for p in files] \n",
    "with open('mimic_ground_truth.yml') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "    \n",
    "d = get_data(data, s, files)\n",
    "fs.append(d[0])\n",
    "accs.append(d[1])\n",
    "scales.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_over_speed(names, scales, forward_speeds_all, accs_all):\n",
    "    d = []\n",
    "    \n",
    "    for n, scale, forward_speeds, accs in zip(names, scales, forward_speeds_all, accs_all):\n",
    "        for m, tmp_fs, tmp_accs in zip(metrics_names, forward_speeds, accs):\n",
    "            for s, fs, a in zip(scale, tmp_fs, tmp_accs):\n",
    "                trace = go.Scatter(\n",
    "                    x = fs,\n",
    "                    y = a,\n",
    "                    name = str(s),\n",
    "                    # legendgroup = o.percentage,\n",
    "                    mode = 'markers',\n",
    "                    text = sequences_val\n",
    "                )\n",
    "                # d.append(trace)\n",
    "\n",
    "            x = []\n",
    "            y = []\n",
    "            for s, fs, a in zip(scale, tmp_fs, tmp_accs):\n",
    "                x.append(np.asarray(fs).mean())\n",
    "                y.append(np.asarray(a).mean())\n",
    "\n",
    "            trace = go.Scatter(\n",
    "                x = x,\n",
    "                y = y,\n",
    "                text = scale,\n",
    "                name = n\n",
    "            )\n",
    "            d.append(trace)\n",
    "        \n",
    "    layout = go.Layout(title='Metric vs Forward Speed',\n",
    "                       font=dict(family='Roboto'),\n",
    "                       xaxis=dict(title='Forward Speed in seconds',  ticks='outside'),\n",
    "                       yaxis=dict(title='Metric value'),\n",
    "                       showlegend=True,\n",
    "                      )\n",
    "    fig = go.Figure(data=d, layout=layout)\n",
    "    py.iplot(fig)\n",
    "    \n",
    "    \n",
    "plot_metric_over_speed(names, scales, fs, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
